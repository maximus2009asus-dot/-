# Прогнозирование отмены бронирования отелей

Данный проект посвящён решению задачи бинарной классификации — прогнозированию отмены бронирования в отелях на основе реальных данных. Используемый набор данных ([Hotel Booking Demand](https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand)) содержит информацию о более чем 119 тыс. бронирований в двух типах отелей за трёхлетний период.

##  Цель
Построить модель машинного обучения, способную с высокой точностью предсказывать, будет ли бронирование отменено (`is_canceled = 1`) или подтверждено (`is_canceled = 0`).

##  Авторы
- Михайличенко Максим Сергеевич  
- Дорджиев Тимур Владимирович

##  Используемые технологии и библиотеки
- **Язык**: Python  
- **ML-библиотеки**: `scikit-learn`, `XGBoost`, `LightGBM`, `CatBoost`  
- **Ансамбли**: `VotingClassifier`, `BaggingClassifier`, `RandomForestClassifier`  
- **Обработка данных**: `pandas`, `numpy`, `LabelEncoder`, `StandardScaler`  
- **Визуализация**: `matplotlib`, `seaborn`, `plotly`, `folium`  
- **Загрузка данных**: `mlcroissant`

##  Этапы предобработки данных
1. **Удаление признаков с большим количеством пропусков**:  
   - Поле `company` удалено (94.3% пропущенных значений).
2. **Заполнение пропусков**:  
   - `agent` — заполнен модой (`9.0`),  
   - `country` — заполнен модой (`'PRT'`),  
   - `children` — заполнен медианой (`0.0`).  
3. **Удаление нерелевантных признаков**, не влияющих на целевую переменную:  
   - `days_in_waiting_list`, `assigned_room_type`, `booking_changes`, `reservation_status`, `country`, `arrival_date_month`, `arrival_date_year`.  
4. **Кодирование категориальных признаков** с помощью `LabelEncoder`.  
5. **Стандартизация числовых признаков** с использованием `StandardScaler`.

##  Обученные модели
Протестирован широкий спектр моделей:
- Базовые: Decision Tree, Logistic Regression, KNN  
- Ансамбли: Hard/Soft Voting, Bagging, Random Forest  
- Градиентный бустинг: XGBoost, LightGBM, CatBoost

##  Результаты всех моделей
+--------- Полное сравнение всех моделей ---------+
Модель                | Accuracy | Precision | Recall | F1-Score
----------------------|----------|-----------|--------|---------
LightGBM              | 0.9993   | 0.9986    | 0.9994 | 0.9990
XGBoost               | 0.9982   | 0.9986    | 0.9964 | 0.9975
CatBoost              | 0.9943   | 0.9982    | 0.9863 | 0.9922
Bagging DT            | 0.9750   | 0.9959    | 0.9363 | 0.9652
Random Forest         | 0.9556   | 0.9828    | 0.8958 | 0.9372
Soft Voting           | 0.9441   | 0.9736    | 0.8728 | 0.9205
Decision Tree         | 0.9231   | 0.8980    | 0.8939 | 0.8959
Hard Voting           | 0.9193   | 0.9806    | 0.7980 | 0.8799
Logistic Regression   | 0.8138   | 0.8946    | 0.5637 | 0.6916
KNN                   | 0.8096   | 0.8013    | 0.6463 | 0.7155


**Лучшая модель**: **LightGBM**  
Точность (Accuracy): **0.9993**

##  Интерпретация признаков (по Random Forest)
Топ-5 наиболее важных признаков:
1. `deposit_type`  
2. `arrival_date_week_number`  
3. `lead_time`  
4. `month`  
5. `day`

## визуализации
- Распределение целевой переменной  
- Анализ пропущенных значений  
- Географическое распределение гостей (`folium`, `plotly choropleth`)  
- Средняя стоимость проживания по месяцам и типу отеля  
- Количество гостей по месяцам  
- Важность признаков  
- Матрицы ошибок для всех ансамблевых моделей

##  Итоги
Проект успешно решил поставленную задачу с **точностью 99.93%**, что делает модель пригодной для практического применения в системах управления бронированиями отелей. LightGBM оказался оптимальным выбором по соотношению **качество/скорость**.
